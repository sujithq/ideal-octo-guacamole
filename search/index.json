[{"content":"Why Use Federated Credentials in CI/CD Pipelines? In DevOps, protecting credentials and preventing secret sprawl across CI/CD systems like GitHub Actions and Azure DevOps is crucial. Federated credentials provide a secure way to authenticate pipelines without storing sensitive information, reducing the risk of exposure and simplifying secret management.\nFederated identity leverages external identity providers (such as Azure Active Directory) to authenticate users and applications securely. Rather than managing multiple secrets or tokens across platforms, federated identity centralizes authentication, providing significant security and operational benefits.\nBenefits of Using Federated Credentials in CI/CD Pipelines 1️⃣ Eliminate Secrets in Pipelines Federated credentials eliminate the need to store sensitive secrets directly within pipeline configurations, significantly reducing the attack surface.\n2️⃣ Centralized Identity Management Using a centralized identity provider simplifies user and app authentication across multiple CI/CD platforms, reducing administrative overhead.\n3️⃣ Enhanced Security Federated authentication allows leveraging advanced security measures such as Multi-Factor Authentication (MFA), conditional access, and identity protection offered by Azure AD.\n4️⃣ Simplified Secret Rotation Federated identities use short-lived, auto-rotated tokens, simplifying credential rotation processes and reducing the risk of credential leaks.\n5️⃣ Improved Compliance and Auditability Centralized identity providers offer robust auditing and compliance capabilities, making it easier to track authentication events and meet regulatory requirements.\n6️⃣ Reduced Administrative Effort By avoiding direct secret management, teams save considerable time and reduce potential human errors in handling credentials.\n7️⃣ Better Collaboration Federated identity streamlines collaboration across teams and organizations by enabling secure and seamless access management through unified authentication.\n8️⃣ Future-Proof Authentication Federated identity solutions scale efficiently and adapt easily to evolving security requirements and organizational growth.\nImplementing Federated Identity in GitHub and Azure DevOps GitHub Actions Integration Federated identity can be integrated directly into GitHub Actions workflows through Azure AD\u0026rsquo;s OIDC provider. This allows pipelines to securely authenticate to Azure without maintaining any secrets in GitHub.\nBelow are clear guidelines to integrate federated credentials using either an Azure AD App Registration or an Azure Managed Identity. Each method includes complete scripts and GitHub workflows.\nGitHub - Method 1: Azure AD App Registration GitHub - Create Azure AD Application with Federated Credential This script automates the setup of an Azure AD App Registration with federated identity, enabling GitHub Actions workflows to securely authenticate to Azure without storing any secrets.\nDetailed Steps:\n1️⃣ Define Variables\nThese variables should be customized with your details:\nAZURE_SUBSCRIPTION_ID: Azure subscription ID for resource access. GH_ORG: GitHub organization or username. GH_REPO: GitHub repository name. GH_BRANCH: Repository branch authorized for authentication (typically main). 2️⃣ Create Azure AD Application and Assign RBAC Role\nresult=$(az ad sp create-for-rbac --role=\u0026#34;Contributor\u0026#34; --scopes=\u0026#34;/subscriptions/$AZURE_SUBSCRIPTION_ID\u0026#34;) AAD_CLIENT_ID=$(echo $result | jq -r \u0026#39;.appId\u0026#39;) AAD_TENANT_ID=$(echo $result | jq -r \u0026#39;.tenant\u0026#39;) Uses Azure CLI to create an Azure AD Service Principal (App Registration). Automatically assigns the Contributor role scoped to your Azure subscription. Captures key identifiers: AAD_CLIENT_ID: Application Client ID for authentication. AAD_TENANT_ID: Azure AD Tenant ID. 3️⃣ Prepare Federated Credential Configuration\ncat \u0026lt;\u0026lt;EOF \u0026gt; params.json { \u0026#34;name\u0026#34;: \u0026#34;${GH_ORG}-${GH_REPO}-federation\u0026#34;, \u0026#34;issuer\u0026#34;: \u0026#34;https://token.actions.githubusercontent.com\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;repo:${GH_ORG}/${GH_REPO}:ref:refs/heads/${GH_BRANCH}\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Federation for GitHub Actions (${GH_ORG}/${GH_REPO})\u0026#34;, \u0026#34;audiences\u0026#34;: [\u0026#34;api://AzureADTokenExchange\u0026#34;] } EOF This JSON configuration defines the federated identity:\nname: A descriptive identifier for the federated credential. issuer: The trusted issuer of the OIDC token from GitHub Actions. subject: Restricts authentication specifically to your GitHub repository and branch, ensuring tight security boundaries. description: A helpful descriptor for easy management. audiences: The intended Azure token exchange audience. 4️⃣ Create the Federated Credential\naz ad app federated-credential create --id $AAD_CLIENT_ID --parameters @params.json Links the federated credential configuration with your Azure AD Application. Enables GitHub Actions workflows to securely authenticate to Azure via short-lived OIDC tokens, eliminating the need for storing secrets. 5️⃣ Output GitHub Secrets\nprintf \u0026#34;Add the following secrets to your GitHub repository:\\n\u0026#34; printf \u0026#34;AZURE_CLIENT_ID=%s\\n\u0026#34; \u0026#34;$AAD_CLIENT_ID\u0026#34; printf \u0026#34;AZURE_TENANT_ID=%s\\n\u0026#34; \u0026#34;$AAD_TENANT_ID\u0026#34; printf \u0026#34;AZURE_SUBSCRIPTION_ID=%s\\n\u0026#34; \u0026#34;$AZURE_SUBSCRIPTION_ID\u0026#34; Outputs critical (non-sensitive) identifiers required for configuring GitHub repository secrets. These identifiers are safe to store as secrets or variables, as they contain no direct credential secrets (e.g., passwords or tokens). ✅ Complete script\n# Variables AZURE_SUBSCRIPTION_ID=\u0026#34;\u0026lt;your-subscription-id\u0026gt;\u0026#34; GH_ORG=\u0026#34;\u0026lt;your-github-org\u0026gt;\u0026#34; GH_REPO=\u0026#34;\u0026lt;your-github-repo\u0026gt;\u0026#34; GH_BRANCH=\u0026#34;main\u0026#34; # Create Azure AD App Registration with RBAC result=$(az ad sp create-for-rbac --role=\u0026#34;Contributor\u0026#34; --scopes=\u0026#34;/subscriptions/$AZURE_SUBSCRIPTION_ID\u0026#34;) AAD_CLIENT_ID=$(echo $result | jq -r \u0026#39;.appId\u0026#39;) AAD_TENANT_ID=$(echo $result | jq -r \u0026#39;.tenant\u0026#39;) # Federated Credential Parameters cat \u0026lt;\u0026lt;EOF \u0026gt; params.json { \u0026#34;name\u0026#34;: \u0026#34;${GH_ORG}-${GH_REPO}-federation\u0026#34;, \u0026#34;issuer\u0026#34;: \u0026#34;https://token.actions.githubusercontent.com\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;repo:${GH_ORG}/${GH_REPO}:ref:refs/heads/${GH_BRANCH}\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Federation for GitHub Actions (${GH_ORG}/${GH_REPO})\u0026#34;, \u0026#34;audiences\u0026#34;: [\u0026#34;api://AzureADTokenExchange\u0026#34;] } EOF # Create Federated Credential az ad app federated-credential create --id $AAD_CLIENT_ID --parameters @params.json # Output required values printf \u0026#34;Add the following secrets to your GitHub repository:\\n\u0026#34; printf \u0026#34;AZURE_CLIENT_ID=%s\\n\u0026#34; \u0026#34;$AAD_CLIENT_ID\u0026#34; printf \u0026#34;AZURE_TENANT_ID=%s\\n\u0026#34; \u0026#34;$AAD_TENANT_ID\u0026#34; printf \u0026#34;AZURE_SUBSCRIPTION_ID=%s\\n\u0026#34; \u0026#34;$AZURE_SUBSCRIPTION_ID\u0026#34; GitHub Actions Workflow (App Registration) This GitHub Actions workflow demonstrates how to securely authenticate to Azure using an Azure AD App Registration with a federated credential, leveraging OpenID Connect (OIDC).\nPipeline Overview\nWorkflow Name:\nAzure AD App Federated Credential\nTrigger:\nExecutes on each push to the main branch.\nRunner:\nUses GitHub\u0026rsquo;s hosted Ubuntu runner (ubuntu-latest).\nStep 1: Checkout Code\n- uses: actions/checkout@v4 Retrieves the latest source code from your repository. 2️⃣ Authenticate to Azure with OIDC\n- uses: azure/login@v2 with: client-id: ${{ secrets.AZURE_CLIENT_ID }} tenant-id: ${{ secrets.AZURE_TENANT_ID }} subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }} Authenticates the workflow to Azure using OIDC, obtaining an Azure token without ever storing secrets directly in the pipeline. Uses the Azure AD App Registration\u0026rsquo;s federated credential configured earlier. Essential GitHub secrets (AZURE_CLIENT_ID, AZURE_TENANT_ID, and AZURE_SUBSCRIPTION_ID) were set up previously. Security Note:\nThe id-token: write permission is crucial, as it enables the workflow to request an OIDC token securely. 3️⃣ Display Subscription Info\n- name: Display Subscription Info uses: azure/cli@v1 with: inlineScript: | az account show --query \u0026#34;name\u0026#34; -o tsv Runs an Azure CLI command to confirm successful authentication by displaying the active Azure subscription name. Demonstrates a basic Azure CLI operation within the authenticated context, indicating readiness for further Azure operations. ✅ Complete script\nname: Azure AD App Federated Credential permissions: id-token: write contents: read on: push: branches: [main] jobs: deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses: azure/login@v2 with: client-id: ${{ secrets.AZURE_CLIENT_ID }} tenant-id: ${{ secrets.AZURE_TENANT_ID }} subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }} - name: Display Subscription Info uses: azure/cli@v1 with: inlineScript: | az account show --query \u0026#34;name\u0026#34; -o tsv GitHub - Method 2: Azure Managed Identity Create Managed Identity with Federated Credential This script automates the setup of an Azure Managed Identity with a federated credential, allowing GitHub Actions workflows to authenticate securely to Azure without storing any secrets.\nDetailed Steps:\nStep 1: Define Variables\nYou must customize these variables:\nAZURE_SUBSCRIPTION_ID: Your Azure subscription identifier. AZURE_RG: Name for the Azure resource group to host the managed identity. AZURE_LOCATION: Azure region to deploy the managed identity (e.g., westeurope). ID_NAME: Name for the Azure Managed Identity resource. GH_ORG: GitHub organization or user name. GH_REPO: GitHub repository name. GH_BRANCH: Repository branch permitted to authenticate (typically main). 2️⃣ Create Resource Group\naz group create --resource-group $AZURE_RG --location $AZURE_LOCATION Creates a resource group in Azure, acting as a container for resources such as the managed identity. 3️⃣ Create Managed Identity\nresult=$(az identity create --name $ID_NAME --resource-group $AZURE_RG) AAD_CLIENT_ID=$(echo $result | jq -r \u0026#39;.clientId\u0026#39;) AAD_PRINCIPAL_ID=$(echo $result | jq -r \u0026#39;.principalId\u0026#39;) AAD_TENANT_ID=$(echo $result | jq -r \u0026#39;.tenantId\u0026#39;) Creates a User-Assigned Managed Identity, capturing the following identifiers: AAD_CLIENT_ID: Application Client ID used for authentication. AAD_PRINCIPAL_ID: Principal ID used for assigning Azure RBAC roles. AAD_TENANT_ID: Tenant ID for your Azure Active Directory instance. 4️⃣ Assign RBAC Role to Managed Identity\naz role assignment create --role \u0026#34;Contributor\u0026#34; --assignee-object-id $AAD_PRINCIPAL_ID --scope /subscriptions/$AZURE_SUBSCRIPTION_ID Grants the Managed Identity the Contributor role at the subscription level. Enables it to perform actions within your Azure subscription securely. 5️⃣ Create Federated Credential\naz identity federated-credential create \\ --name \u0026#34;${GH_ORG}-${GH_REPO}-federation\u0026#34; \\ --identity-name $ID_NAME \\ --resource-group $AZURE_RG \\ --issuer \u0026#34;https://token.actions.githubusercontent.com\u0026#34; \\ --subject \u0026#34;repo:${GH_ORG}/${GH_REPO}:ref:refs/heads/${GH_BRANCH}\u0026#34; \\ --audiences \u0026#34;api://AzureADTokenExchange\u0026#34; Establishes a federated identity between Azure and GitHub Actions using OIDC: issuer: GitHub Actions OIDC token issuer URL. subject: Restricts authentication to your specific GitHub repository and branch. audiences: Configured audience that Azure expects for authentication via token exchange. This federated credential allows your GitHub Actions workflow to authenticate with Azure automatically without directly storing sensitive credentials.\n6️⃣ Output Required GitHub Secrets\nprintf \u0026#34;Add the following secrets to your GitHub repository:\\n\u0026#34; printf \u0026#34;AZURE_CLIENT_ID=%s\\n\u0026#34; \u0026#34;$AAD_CLIENT_ID\u0026#34; printf \u0026#34;AZURE_TENANT_ID=%s\\n\u0026#34; \u0026#34;$AAD_TENANT_ID\u0026#34; printf \u0026#34;AZURE_SUBSCRIPTION_ID=%s\\n\u0026#34; \u0026#34;$AZURE_SUBSCRIPTION_ID\u0026#34; Displays critical values that must be added as GitHub repository secrets: AZURE_CLIENT_ID AZURE_TENANT_ID AZURE_SUBSCRIPTION_ID These variables do not store sensitive passwords or secrets directly—only identifiers necessary for the authentication process.\n✅ Complete script\n# Variables AZURE_SUBSCRIPTION_ID=\u0026#34;\u0026lt;your-subscription-id\u0026gt;\u0026#34; AZURE_RG=\u0026#34;rg-gh-oidc\u0026#34; AZURE_LOCATION=\u0026#34;westeurope\u0026#34; ID_NAME=\u0026#34;id-gh-oidc\u0026#34; GH_ORG=\u0026#34;\u0026lt;your-github-org\u0026gt;\u0026#34; GH_REPO=\u0026#34;\u0026lt;your-github-repo\u0026gt;\u0026#34; GH_BRANCH=\u0026#34;main\u0026#34; # Create Resource Group az group create --resource-group $AZURE_RG --location $AZURE_LOCATION # Create Managed Identity result=$(az identity create --name $ID_NAME --resource-group $AZURE_RG) AAD_CLIENT_ID=$(echo $result | jq -r \u0026#39;.clientId\u0026#39;) AAD_PRINCIPAL_ID=$(echo $result | jq -r \u0026#39;.principalId\u0026#39;) AAD_TENANT_ID=$(echo $result | jq -r \u0026#39;.tenantId\u0026#39;) # Assign RBAC role to Managed Identity az role assignment create --role \u0026#34;Contributor\u0026#34; --assignee-object-id $AAD_PRINCIPAL_ID --scope /subscriptions/$AZURE_SUBSCRIPTION_ID # Create Federated Credential az identity federated-credential create \\ --name \u0026#34;${GH_ORG}-${GH_REPO}-federation\u0026#34; \\ --identity-name $ID_NAME \\ --resource-group $AZURE_RG \\ --issuer \u0026#34;https://token.actions.githubusercontent.com\u0026#34; \\ --subject \u0026#34;repo:${GH_ORG}/${GH_REPO}:ref:refs/heads/${GH_BRANCH}\u0026#34; \\ --audiences \u0026#34;api://AzureADTokenExchange\u0026#34; # Output required values printf \u0026#34;Add the following secrets to your GitHub repository:\\n\u0026#34; printf \u0026#34;AZURE_CLIENT_ID=%s\\n\u0026#34; \u0026#34;$AAD_CLIENT_ID\u0026#34; printf \u0026#34;AZURE_TENANT_ID=%s\\n\u0026#34; \u0026#34;$AAD_TENANT_ID\u0026#34; printf \u0026#34;AZURE_SUBSCRIPTION_ID=%s\\n\u0026#34; \u0026#34;$AZURE_SUBSCRIPTION_ID\u0026#34; GitHub Actions Workflow (Managed Identity) name: Azure Managed Identity Federated Credential permissions: id-token: write contents: read on: push: branches: [main] jobs: deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses: azure/login@v2 with: client-id: ${{ secrets.AZURE_CLIENT_ID }} tenant-id: ${{ secrets.AZURE_TENANT_ID }} subscription-id: ${{ secrets.AZURE_SUBSCRIPTION_ID }} - name: Display Subscription Info uses: azure/cli@v1 with: inlineScript: | az account show --query \u0026#34;name\u0026#34; -o tsv Azure DevOps Pipelines Integration Federated identity integration with Azure DevOps pipelines allows secure, secretless authentication to Azure resources using Azure AD\u0026rsquo;s built-in OIDC support. This prevents credential leaks and reduces the spread of secrets across your DevOps pipelines.\nBelow are clear guidelines to integrate federated credentials using either an Azure AD App Registration or an Azure Managed Identity. Each method includes complete scripts and Azure DevOps pipelines.\nAzure DevOps - Method 1: Azure AD App Registration Azure DevOps - Create Azure AD Application with Federated Credential This script automates the creation and configuration of an Azure DevOps Service Connection using OpenID Connect (OIDC) federation with an Azure AD App Registration. This enables Azure DevOps Pipelines to authenticate securely to Azure without storing secrets in the pipeline.\nDetailed Steps:\n1. Variables Initialization\nYou must customize these variables according to your environment:\nAZURE_SUBSCRIPTION_ID: Your Azure subscription ID. AZDO_ORGANIZATION_NAME: Azure DevOps organization name (e.g., myorg). AZDO_PROJECT_NAME: Azure DevOps project name. AZDO_SERVICE_ENDPOINT_NAME: Name for the Azure DevOps Service Connection. 2. Azure Subscription Name Retrieval\nresult=$(az account show -s $AZURE_SUBSCRIPTION_ID) AZURE_SUBSCRIPTION_NAME=$(echo $result | jq -r \u0026#39;.name\u0026#39;) Fetches the Azure subscription details. Captures the subscription name to be used in subsequent configurations. 3. Azure DevOps CLI Configuration\nAZDO_BASE_URL=\u0026#34;https://dev.azure.com/$AZDO_ORGANIZATION_NAME\u0026#34; az devops configure --defaults organization=$AZDO_BASE_URL Sets the Azure DevOps CLI default organization context for subsequent commands. 4. Azure DevOps Project Creation\nif ! az devops project list | jq -e --arg PROJECT_NAME \u0026#34;$AZDO_PROJECT_NAME\u0026#34; \u0026#39;.[] | select(.name == $PROJECT_NAME)\u0026#39; \u0026gt; /dev/null; then az devops project create --name $AZDO_PROJECT_NAME --description $AZDO_PROJECT_NAME --visibility private fi Checks if the Azure DevOps project already exists. Creates the project if it doesn\u0026rsquo;t exist (with private visibility). 5. Azure AD Application (Service Principal) Creation\nresult=$(az ad sp create-for-rbac --role=\u0026#34;Contributor\u0026#34; \\ --scopes=\u0026#34;/subscriptions/$AZURE_SUBSCRIPTION_ID\u0026#34; \\ --name app-$AZDO_ORGANIZATION_NAME-azdo-oidc) AAD_CLIENT_ID=$(echo $result | jq -r \u0026#39;.appId\u0026#39;) AAD_TENANT_ID=$(echo $result | jq -r \u0026#39;.tenant\u0026#39;) Creates an Azure AD Service Principal with the Contributor role scoped to your Azure subscription. Captures necessary identifiers (AAD_CLIENT_ID and AAD_TENANT_ID) for authentication. 6. Azure DevOps Service Endpoint Configuration\nThe script creates a JSON file (params.azdo.json) that defines an Azure RM (Resource Manager) service endpoint with federated authentication parameters:\nauthorization.scheme: Set as WorkloadIdentityFederation to use OIDC. Provides details like subscription ID, subscription name, tenant ID, and service principal client ID. { \u0026#34;data\u0026#34;: { \u0026#34;subscriptionId\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;subscriptionName\u0026#34;: \u0026#34;...\u0026#34; }, \u0026#34;authorization\u0026#34;: { \u0026#34;parameters\u0026#34;: { \u0026#34;serviceprincipalid\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;tenantid\u0026#34;: \u0026#34;...\u0026#34; }, \u0026#34;scheme\u0026#34;: \u0026#34;WorkloadIdentityFederation\u0026#34; }, ... } 7. Azure DevOps Service Endpoint Creation or Retrieval\nif ! az devops service-endpoint list --project $AZDO_PROJECT_NAME | jq -e --arg SE_NAME \u0026#34;$AZDO_SERVICE_ENDPOINT_NAME\u0026#34; \u0026#39;.[] | select(.name == $SE_NAME)\u0026#39; \u0026gt; /dev/null; then result=$(az devops service-endpoint create \\ --service-endpoint-configuration params.azdo.json \\ --organization $AZDO_BASE_URL \\ --project $AZDO_PROJECT_NAME \\ --detect true) SERVICE_ENDPOINT_ID=$(echo $result | jq -r \u0026#39;.id\u0026#39;) else SERVICE_ENDPOINT_ID=$(az devops service-endpoint list \\ --project $AZDO_PROJECT_NAME | jq -r \\ --arg NAME \u0026#34;$AZDO_SERVICE_ENDPOINT_NAME\u0026#34; \u0026#39;.[] | select(.name==$NAME) | .id\u0026#39;) result=$(az devops service-endpoint show \\ --project $AZDO_PROJECT_NAME \\ --id $SERVICE_ENDPOINT_ID) fi Checks if the Service Endpoint already exists in the project. Creates the endpoint if it doesn’t exist, or retrieves existing endpoint details. Captures key identifiers like SERVICE_ENDPOINT_ID. 8. Retrieve Issuer and Subject from Service Endpoint\nSERVICE_ENDPOINT_ISSUER=$(echo $result | jq -r \u0026#39;.authorization.parameters.workloadIdentityFederationIssuer\u0026#39;) SERVICE_ENDPOINT_SUBJECT=$(echo $result | jq -r \u0026#39;.authorization.parameters.workloadIdentityFederationSubject\u0026#39;) Retrieves the Issuer URL and Subject claim from the Service Endpoint configuration, needed for Azure AD federated credential setup. 9. Federated Credential Creation or Update\nThe script prepares two JSON configuration files for Azure AD federated credential:\nparams.create.json (used for initial creation) params.update.json (used for subsequent updates) Both files specify the following properties:\nname: Credential identifier. issuer: Token issuer URL from Azure DevOps. subject: Subject claim that uniquely identifies the Azure DevOps Service Endpoint. audiences: Specifies \u0026quot;api://AzureADTokenExchange\u0026quot; as the audience for OIDC. { \u0026#34;name\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;issuer\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;...\u0026#34;, \u0026#34;audiences\u0026#34;: [\u0026#34;api://AzureADTokenExchange\u0026#34;] } Then it checks whether the federated credential already exists:\nif ! az ad app federated-credential list --id $AAD_CLIENT_ID | jq -e --arg NAME \u0026#34;$PARAMS_NAME\u0026#34; \u0026#39;.[] | select(.name == $NAME)\u0026#39; \u0026gt; /dev/null; then az ad app federated-credential create --id $AAD_CLIENT_ID --parameters params.create.json else FEDERATED_CREDENTIAL_ID=$(az ad app federated-credential list --id $AAD_CLIENT_ID | jq -r -e --arg NAME \u0026#34;$PARAMS_NAME\u0026#34; \u0026#39;.[] | select(.name == $NAME) | .id\u0026#39;) az ad app federated-credential update --id $AAD_CLIENT_ID --federated-credential-id $FEDERATED_CREDENTIAL_ID --parameters params.update.json fi Creates a new federated credential linking Azure DevOps and Azure AD, or updates the existing one if needed. ✅ Complete script\n# Variables # Azure Subscription Id AZURE_SUBSCRIPTION_ID=\u0026#34;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\u0026#34; # Azure DevOps Organization Name AZDO_ORGANIZATION_NAME=\u0026#34;\u0026lt;myorg\u0026gt;\u0026#34; # Azure DevOps Project Name AZDO_PROJECT_NAME=\u0026#34;\u0026lt;myproject\u0026gt;\u0026#34; # Azure DevOps Service Account Name AZDO_SERVICE_ENDPOINT_NAME=\u0026#34;\u0026lt;mysvcconnection\u0026gt;\u0026#34; # Azure Subscription Name result=$(az account show -s $AZURE_SUBSCRIPTION_ID) AZURE_SUBSCRIPTION_NAME=$(echo $result | jq -r \u0026#39;.name\u0026#39;) # Azure DevOps base URL AZDO_BASE_URL=\u0026#34;https://dev.azure.com/$AZDO_ORGANIZATION_NAME\u0026#34; # Set Azure DevOps defaults result=$(az devops configure --defaults organization=$AZDO_BASE_URL) # Create DevOps Project if ! az devops project list | jq -e --arg PROJECT_NAME \u0026#34;$AZDO_PROJECT_NAME\u0026#34; \u0026#39;.[] | select(.name == $PROJECT_NAME)\u0026#39; \u0026gt; /dev/null; then result=$(az devops project create --name $AZDO_PROJECT_NAME --description $AZDO_PROJECT_NAME --visibility private) fi # Create App Registration result=$(az ad sp create-for-rbac --role=\u0026#34;Contributor\u0026#34; --scopes=\u0026#34;/subscriptions/$AZURE_SUBSCRIPTION_ID\u0026#34; --name app-$AZDO_ORGANIZATION_NAME-azdo-oidc) # Get AAD Application Id AAD_CLIENT_ID=$(echo $result | jq -r \u0026#39;.appId\u0026#39;) AAD_TENANT_ID=$(echo $result | jq -r \u0026#39;.tenant\u0026#39;) # Create Service Endpoint Configuration params file params.azdo.json cat \u0026lt;\u0026lt;EOF \u0026gt; params.azdo.json { \u0026#34;data\u0026#34;: { \u0026#34;subscriptionId\u0026#34;: \u0026#34;${AZURE_SUBSCRIPTION_ID}\u0026#34;, \u0026#34;subscriptionName\u0026#34;: \u0026#34;$AZURE_SUBSCRIPTION_NAME\u0026#34; }, \u0026#34;authorization\u0026#34;: { \u0026#34;parameters\u0026#34;: { \u0026#34;serviceprincipalid\u0026#34;: \u0026#34;${AAD_CLIENT_ID}\u0026#34;, \u0026#34;tenantid\u0026#34;: \u0026#34;${AAD_TENANT_ID}\u0026#34; }, \u0026#34;scheme\u0026#34;: \u0026#34;WorkloadIdentityFederation\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#34;, \u0026#34;serviceEndpointProjectReferences\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#34;, \u0026#34;projectReference\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;${AZDO_PROJECT_NAME}\u0026#34; } } ], \u0026#34;type\u0026#34;: \u0026#34;azurerm\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://management.azure.com/\u0026#34; } EOF # Create Or Get Service Endpoint if ! az devops service-endpoint list --project $AZDO_PROJECT_NAME | jq -e --arg SE_NAME \u0026#34;$AZDO_SERVICE_ENDPOINT_NAME\u0026#34; \u0026#39;.[] | select(.name == $SE_NAME)\u0026#39; \u0026gt; /dev/null; then result=$(az devops service-endpoint create --service-endpoint-configuration params.azdo.json --organization $AZDO_BASE_URL --project $AZDO_PROJECT_NAME --detect true) # Service Endpoint Id SERVICE_ENDPOINT_ID=$(echo $result | jq -r \u0026#39;.id\u0026#39;) else # Service Endpoint Id SERVICE_ENDPOINT_ID=$(az devops service-endpoint list --project $AZDO_PROJECT_NAME | jq -r --arg NAME \u0026#34;$AZDO_SERVICE_ENDPOINT_NAME\u0026#34; \u0026#39;.[] | select(.name==$NAME) | .id\u0026#39;) result=$(az devops service-endpoint show --project $AZDO_PROJECT_NAME --id $SERVICE_ENDPOINT_ID) fi # Service Endpoint Issuer SERVICE_ENDPOINT_ISSUER=$(echo $result | jq -r \u0026#39;.authorization.parameters.workloadIdentityFederationIssuer\u0026#39;) # Service Endpoint Subject SERVICE_ENDPOINT_SUBJECT=$(echo $result | jq -r \u0026#39;.authorization.parameters.workloadIdentityFederationSubject\u0026#39;) # Create Federated Credential Configuration params file params.json PARAMS_NAME=\u0026#34;$AZDO_PROJECT_NAME-federated-identity\u0026#34; PARAMS_ISSUER=\u0026#34;${SERVICE_ENDPOINT_ISSUER}\u0026#34; PARAMS_SUBJECT=\u0026#34;${SERVICE_ENDPOINT_SUBJECT}\u0026#34; PARAMS_DESCRIPTION=\u0026#34;Federation for Service Connection $AZDO_SERVICE_ENDPOINT_NAME in $AZDO_BASE_URL/$AZDO_PROJECT_NAME/_settings/adminservices?resourceId=$SERVICE_ENDPOINT_ID\u0026#34; cat \u0026lt;\u0026lt;EOF \u0026gt; params.create.json { \u0026#34;name\u0026#34;: \u0026#34;${PARAMS_NAME}\u0026#34;, \u0026#34;issuer\u0026#34;: \u0026#34;${SERVICE_ENDPOINT_ISSUER}\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;${PARAMS_SUBJECT}\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;${PARAMS_DESCRIPTION}\u0026#34;, \u0026#34;audiences\u0026#34;: [ \u0026#34;api://AzureADTokenExchange\u0026#34; ] } EOF cat \u0026lt;\u0026lt;EOF \u0026gt; params.update.json { \u0026#34;issuer\u0026#34;: \u0026#34;${SERVICE_ENDPOINT_ISSUER}\u0026#34;, \u0026#34;subject\u0026#34;: \u0026#34;${PARAMS_SUBJECT}\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;${PARAMS_DESCRIPTION}\u0026#34;, \u0026#34;audiences\u0026#34;: [ \u0026#34;api://AzureADTokenExchange\u0026#34; ] } EOF # Create Or Update Federated Credential if ! az ad app federated-credential list --id $AAD_CLIENT_ID | jq -e --arg NAME \u0026#34;$PARAMS_NAME\u0026#34; \u0026#39;.[] | select(.name == $NAME)\u0026#39; \u0026gt; /dev/null; then result=$(az ad app federated-credential create --id $AAD_CLIENT_ID --parameters params.create.json) else FEDERATED_CREDENTIAL_ID=$(az ad app federated-credential list --id $AAD_CLIENT_ID | jq -r -e --arg NAME \u0026#34;$PARAMS_NAME\u0026#34; \u0026#39;.[] | select(.name == $NAME) | .id\u0026#39;) result=$(az ad app federated-credential update --id $AAD_CLIENT_ID --federated-credential-id $FEDERATED_CREDENTIAL_ID --parameters params.update.json) fi Azure DevOps - YAML Pipeline (App Registration) This script automates the following tasks:\nCloning an Azure DevOps Git repository. Adding a pipeline YAML definition. Committing and pushing pipeline changes. Creating a pipeline in Azure DevOps that leverages a federated identity service connection. Detailed Steps:\n1. Clone Azure DevOps Repository\ngit clone https://$AZDO_ORGANIZATION_NAME@dev.azure.com/$AZDO_ORGANIZATION_NAME/$AZDO_PROJECT_NAME/_git/$AZDO_PROJECT_NAME cd $AZDO_PROJECT_NAME Clones your Azure DevOps repository locally using HTTPS authentication. Navigates into the cloned repository folder. 2. Set Variables for Pipeline\nPIPELINE_DIR=\u0026#34;pipelines\u0026#34; IDENTITY_TYPE=\u0026#34;sp\u0026#34; PIPELINE_DIR: Directory to store pipeline YAML files. IDENTITY_TYPE: Identifier (e.g., \u0026ldquo;sp\u0026rdquo; for service principal) used to name the pipeline YAML file clearly. 3. Create Pipeline Directory\nif [ ! -d \u0026#34;$PIPELINE_DIR\u0026#34; ]; then mkdir $PIPELINE_DIR fi Checks if the directory for pipelines exists, creating it if necessary. 4. Generate Azure DevOps Pipeline YAML\nCreates a pipeline YAML file at pipelines/sp.yaml:\ntrigger: - main pool: vmImage: ubuntu-latest steps: - task: AzureCLI@2 inputs: azureSubscription: \u0026#39;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#39; scriptType: \u0026#39;pscore\u0026#39; scriptLocation: \u0026#39;inlineScript\u0026#39; inlineScript: | az account show --query id -o tsv Trigger: Runs on every commit to the main branch. Agent pool: Uses a hosted Ubuntu image (ubuntu-latest). Task: Executes an Azure CLI command: Uses the Azure service connection (AZDO_SERVICE_ENDPOINT_NAME) with federated identity. Displays the Azure subscription ID to verify connectivity. 5. Commit and Push Pipeline YAML\ngit config --global user.name $GIT_USER git config --global user.email $GIT_EMAIL if ! git diff --quiet HEAD -- \u0026#34;./$PIPELINE_DIR/$IDENTITY_TYPE.yaml\u0026#34; ; then git add ./$PIPELINE_DIR/$IDENTITY_TYPE.yaml git commit -m \u0026#34;📊 Add or Update pipeline.\u0026#34; git push origin main else echo \u0026#34;Nothing to commit.\u0026#34; fi Sets Git global user configuration (required for commits). Checks if the pipeline YAML file has changed: If changed, commits and pushes updates. If unchanged, skips the commit. 6. Configure Azure DevOps CLI and Create Pipeline\naz devops configure --defaults organization=$AZDO_BASE_URL az pipelines create \\ --name \u0026#34;$IDENTITY_TYPE-pipeline\u0026#34; \\ --description \u0026#34;This is a sample pipeline to use federated identity\u0026#34; \\ --repository $AZDO_PROJECT_NAME \\ --repository-type tfsgit \\ --branch main \\ --yaml-path $PIPELINE_DIR/$IDENTITY_TYPE.yaml \\ --project $AZDO_PROJECT_NAME Configures Azure DevOps CLI defaults for subsequent commands. Creates the Azure DevOps pipeline with the specified configuration: name: Pipeline name (sp-pipeline). description: Human-readable pipeline description. repository: The Azure DevOps Git repository hosting the pipeline YAML. branch: Branch to monitor (main). yaml-path: Path to the pipeline YAML file. project: Azure DevOps project name. ✅ Complete scripts\ngit clone https://$AZDO_ORGANIZATION_NAME@dev.azure.com/$AZDO_ORGANIZATION_NAME/$AZDO_PROJECT_NAME/_git/$AZDO_PROJECT_NAME cd $AZDO_PROJECT_NAME PIPELINE_DIR=\u0026#34;pipelines\u0026#34; IDENTITY_TYPE=\u0026#34;sp\u0026#34; # Create directory if not exists if [ ! -d \u0026#34;$PIPELINE_DIR\u0026#34; ]; then mkdir $PIPELINE_DIR fi # Store pipeline cat \u0026lt;\u0026lt;EOF \u0026gt; $PIPELINE_DIR/$IDENTITY_TYPE.yaml trigger: - main pool: vmImage: ubuntu-latest steps: - task: AzureCLI@2 inputs: azureSubscription: \u0026#39;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#39; scriptType: \u0026#39;pscore\u0026#39; scriptLocation: \u0026#39;inlineScript\u0026#39; inlineScript: | az account show --query id -o tsv EOF # Commit pipeline git config --global user.name $GIT_USER git config --global user.email $GIT_EMAIL if ! git diff --quiet HEAD -- \u0026#34;./$PIPELINE_DIR/$IDENTITY_TYPE.yaml\u0026#34; ; then git add ./$PIPELINE_DIR/$IDENTITY_TYPE.yaml git commit -m \u0026#34;📊 Add or Update pipeline.\u0026#34; git push origin main else echo \u0026#34;Nothing to commit.\u0026#34; fi az devops configure --defaults organization=$AZDO_BASE_URL az pipelines create \\ --name \u0026#34;$IDENTITY_TYPE-pipeline\u0026#34; \\ --description \u0026#34;This is a sample pipeline to use federated identity\u0026#34; \\ --repository $AZDO_PROJECT_NAME \\ --repository-type tfsgit \\ --branch main \\ --yaml-path $PIPELINE_DIR/$IDENTITY_TYPE.yaml \\ --project $AZDO_PROJECT_NAME Note: Ensure the pipeline has the setting \u0026ldquo;Allow scripts to access the OAuth token\u0026rdquo; enabled (System.AccessToken) under pipeline options.\nAzure DevOps - Method 2: Azure Managed Identity Azure DevOps - Create Managed Identity with Federated Credential This script sets up an end-to-end secure integration between Azure DevOps pipelines and Azure using User-Assigned Managed Identity combined with Federated Identity (OIDC). This allows Azure DevOps pipelines to securely authenticate to Azure without storing secrets directly.\nDetailed Steps:\nStep 1: Define Variables\nVariables you customize at the top of the script:\nAzure Subscription Info:\nAZURE_SUBSCRIPTION_ID: ID of your Azure subscription. AZURE_LOCATION: Azure region (e.g., westeurope). Azure DevOps Info:\nAZDO_ORGANIZATION_NAME: Your Azure DevOps organization name. AZDO_PROJECT_NAME: Your Azure DevOps project name. AZDO_SERVICE_ENDPOINT_NAME: Name of the Azure DevOps Service Connection. Git Config (used later for pipeline commits):\nGIT_USER: Your Git username. GIT_EMAIL: Your Git email. 2️⃣ Azure Resource Group and Managed Identity Creation\nThe script creates a resource group and managed identity for authentication:\naz group create --location $AZURE_LOCATION --name $AZURE_RG result=$(az identity create --name $ID_NAME --resource-group $AZURE_RG) MI_ID=$(echo $result | jq -r \u0026#39;.id\u0026#39;) AAD_CLIENT_ID=$(echo $result | jq -r \u0026#39;.clientId\u0026#39;) AAD_PRINICIPAL_ID=$(echo $result | jq -r \u0026#39;.principalId\u0026#39;) AAD_TENANT_ID=$(echo $result | jq -r \u0026#39;.tenantId\u0026#39;) A Resource Group is created to host the Managed Identity. A User-Assigned Managed Identity is created: AAD_CLIENT_ID: Used to authenticate from Azure DevOps. AAD_PRINICIPAL_ID: Needed for Azure RBAC assignments. AAD_TENANT_ID: Azure AD Tenant identifier. 3️⃣ Assign RBAC Role to Managed Identity\nAssign the Managed Identity the Contributor role on the specified Azure subscription:\naz role assignment create \\ --role \u0026#34;Contributor\u0026#34; \\ --assignee-object-id $AAD_PRINICIPAL_ID \\ --assignee-principal-type ServicePrincipal \\ --scope /subscriptions/$AZURE_SUBSCRIPTION_ID This grants the Managed Identity permissions to perform Azure operations in your subscription.\n4️⃣ Azure DevOps Configuration\nSet Azure DevOps CLI defaults and ensure the project exists:\naz devops configure --defaults organization=$AZDO_BASE_URL if ! az devops project list | jq -e --arg PROJECT_NAME \u0026#34;$AZDO_PROJECT_NAME\u0026#34; \u0026#39;.value[] | select(.name == $PROJECT_NAME)\u0026#39; \u0026gt; /dev/null; then az devops project create \\ --name $AZDO_PROJECT_NAME \\ --description $AZDO_PROJECT_NAME \\ --visibility private fi Configures Azure DevOps CLI context. Creates the Azure DevOps project if it doesn’t already exist. 5️⃣ Create Azure DevOps Service Endpoint with Federated Identity\nA service endpoint configuration (params.azdo.json) is created using Managed Identity and OIDC federation:\nAuthentication uses the scheme: \u0026quot;WorkloadIdentityFederation\u0026quot;. References the Managed Identity’s clientId and tenantId. The script checks if the Service Endpoint exists, creates it if not:\nif ! az devops service-endpoint list --project $AZDO_PROJECT_NAME | jq -e --arg SE_NAME \u0026#34;$AZDO_SERVICE_ENDPOINT_NAME\u0026#34; \u0026#39;.[] | select(.name == $SE_NAME)\u0026#39; \u0026gt; /dev/null; then result=$(az devops service-endpoint create \\ --service-endpoint-configuration params.azdo.json \\ --organization $AZDO_BASE_URL \\ --project $AZDO_PROJECT_NAME \\ --detect true) SERVICE_ENDPOINT_ID=$(echo $result | jq -r \u0026#39;.id\u0026#39;) else SERVICE_ENDPOINT_ID=$(az devops service-endpoint list \\ --project $AZDO_PROJECT_NAME | jq -r \\ --arg NAME \u0026#34;$AZDO_SERVICE_ENDPOINT_NAME\u0026#34; \u0026#39;.[] | select(.name==$NAME) | .id\u0026#39;) result=$(az devops service-endpoint show \\ --project $AZDO_PROJECT_NAME \\ --id $SERVICE_ENDPOINT_ID) fi 6️⃣ Extracting Federated Credential Information\nFrom the Service Endpoint, it retrieves critical parameters needed for OIDC federation:\nSERVICE_ENDPOINT_ISSUER=$(echo $result | jq -r \u0026#39;.authorization.parameters.workloadIdentityFederationIssuer\u0026#39;) SERVICE_ENDPOINT_SUBJECT=$(echo $result | jq -r \u0026#39;.authorization.parameters.workloadIdentityFederationSubject\u0026#39;) Issuer: The trusted OIDC token issuer URL from Azure DevOps. Subject: Unique identifier scoped specifically to your Azure DevOps service endpoint. 7️⃣ Create or Update Azure Managed Identity Federated Credential**\nUsing the issuer and subject obtained above, the script creates or updates the federated credential for the Managed Identity:\nif ! az identity federated-credential list --identity-name $ID_NAME --resource-group $AZURE_RG | jq -e --arg NAME \u0026#34;$PARAMS_NAME\u0026#34; \u0026#39;.[] | select(.name == $NAME)\u0026#39; \u0026gt; /dev/null; then az identity federated-credential create \\ --identity-name $ID_NAME \\ --name $PARAMS_NAME \\ --resource-group $AZURE_RG \\ --audiences \u0026#34;api://AzureADTokenExchange\u0026#34; \\ --issuer $SERVICE_ENDPOINT_ISSUER \\ --subject $SERVICE_ENDPOINT_SUBJECT else az identity federated-credential update \\ --identity-name $ID_NAME \\ --name $PARAMS_NAME \\ --resource-group $AZURE_RG \\ --audiences \u0026#34;api://AzureADTokenExchange\u0026#34; \\ --issuer $SERVICE_ENDPOINT_ISSUER \\ --subject $SERVICE_ENDPOINT_SUBJECT fi Links the Managed Identity securely with Azure DevOps using OIDC federation. Ensures Azure DevOps Pipelines can authenticate securely without stored credentials. ✅ Complete script\n# Variables GIT_USER=\u0026#34;Sujith Quintelier\u0026#34; GIT_EMAIL=\u0026#34;squintelier@company.com\u0026#34; # Azure Subscription Id AZURE_SUBSCRIPTION_ID=\u0026#34;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\u0026#34; # Azure location AZURE_LOCATION=\u0026#34;westeurope\u0026#34; # Azure DevOps Project Name AZDO_PROJECT_NAME=\u0026#34;\u0026lt;myproject\u0026gt;\u0026#34; # Azure DevOps Organization Name AZDO_ORGANIZATION_NAME=\u0026#34;\u0026lt;myorg\u0026gt;\u0026#34; # Azure DevOps Service Account Name AZDO_SERVICE_ENDPOINT_NAME=\u0026#34;\u0026lt;mysvcconnection\u0026gt;\u0026#34; # Azure Resource Group AZURE_RG=\u0026#34;rg-$AZDO_PROJECT_NAME\u0026#34; # Managed Identity Name ID_NAME=\u0026#34;id-$AZDO_PROJECT_NAME\u0026#34; # squintelier|xpirit AZDO_BASE_URL=\u0026#34;https://dev.azure.com/$AZDO_ORGANIZATION_NAME\u0026#34; # Azure DevOps base URL # Azure Subscription Name result=$(az account show -s $AZURE_SUBSCRIPTION_ID) AZURE_SUBSCRIPTION_NAME=$(echo $result | jq -r \u0026#39;.name\u0026#39;) # Set Azure DevOps defaults result=$(az devops configure --defaults organization=$AZDO_BASE_URL) # Create DevOps Project if ! az devops project list | jq -e --arg PROJECT_NAME \u0026#34;$AZDO_PROJECT_NAME\u0026#34; \u0026#39;.value[] | select(.name == $PROJECT_NAME)\u0026#39; \u0026gt; /dev/null; then result=$(az devops project create --name $AZDO_PROJECT_NAME --description $AZDO_PROJECT_NAME --visibility private) fi # Create Resource Group result=$(az group create --location $AZURE_LOCATION --name $AZURE_RG) # Create Managed Identity result=$(az identity create --name $ID_NAME --resource-group $AZURE_RG) # Managed Identity Id MI_ID=$(echo $result | jq -r \u0026#39;.id\u0026#39;) # AAD Application Id AAD_CLIENT_ID=$(echo $result | jq -r \u0026#39;.clientId\u0026#39;) # AAD Principal Id AAD_PRINICIPAL_ID=$(echo $result | jq -r \u0026#39;.principalId\u0026#39;) # AAD Tenant Id AAD_TENANT_ID=$(echo $result | jq -r \u0026#39;.tenantId\u0026#39;) # Role Assignment # # With Graph Permissions (uncomment below) # az role assignment create --role \u0026#34;Contributor\u0026#34; --assignee $MI_ID --scope /subscriptions/$AZURE_SUBSCRIPTION_ID # # Without Graph Permissions (uncomment below) az role assignment create --role \u0026#34;Contributor\u0026#34; --assignee-object-id $AAD_PRINICIPAL_ID --assignee-principal-type ServicePrincipal --scope /subscriptions/$AZURE_SUBSCRIPTION_ID # Create Service Endpoint Configuration params file params.azdo.json cat \u0026lt;\u0026lt;EOF \u0026gt; params.azdo.json { \u0026#34;data\u0026#34;: { \u0026#34;subscriptionId\u0026#34;: \u0026#34;${AZURE_SUBSCRIPTION_ID}\u0026#34;, \u0026#34;subscriptionName\u0026#34;: \u0026#34;$AZURE_SUBSCRIPTION_NAME\u0026#34; }, \u0026#34;authorization\u0026#34;: { \u0026#34;parameters\u0026#34;: { \u0026#34;serviceprincipalid\u0026#34;: \u0026#34;${AAD_CLIENT_ID}\u0026#34;, \u0026#34;tenantid\u0026#34;: \u0026#34;${AAD_TENANT_ID}\u0026#34; }, \u0026#34;scheme\u0026#34;: \u0026#34;WorkloadIdentityFederation\u0026#34; }, \u0026#34;description\u0026#34;: \u0026#34;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#34;, \u0026#34;serviceEndpointProjectReferences\u0026#34;: [ { \u0026#34;description\u0026#34;: \u0026#34;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#34;, \u0026#34;projectReference\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;${AZDO_PROJECT_NAME}\u0026#34; } } ], \u0026#34;type\u0026#34;: \u0026#34;azurerm\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://management.azure.com/\u0026#34; } EOF # Create Or Get Service Endpoint if ! az devops service-endpoint list --project $AZDO_PROJECT_NAME | jq -e --arg SE_NAME \u0026#34;$AZDO_SERVICE_ENDPOINT_NAME\u0026#34; \u0026#39;.[] | select(.name == $SE_NAME)\u0026#39; \u0026gt; /dev/null; then result=$(az devops service-endpoint create --service-endpoint-configuration params.azdo.json --organization $AZDO_BASE_URL --project $AZDO_PROJECT_NAME --detect true) # Service Endpoint Id SERVICE_ENDPOINT_ID=$(echo $result | jq -r \u0026#39;.id\u0026#39;) else # Service Endpoint Id SERVICE_ENDPOINT_ID=$(az devops service-endpoint list --project $AZDO_PROJECT_NAME | jq -r --arg NAME \u0026#34;$AZDO_SERVICE_ENDPOINT_NAME\u0026#34; \u0026#39;.[] | select(.name==$NAME) | .id\u0026#39;) result=$(az devops service-endpoint show --project $AZDO_PROJECT_NAME --id $SERVICE_ENDPOINT_ID) fi # Service Endpoint Issuer SERVICE_ENDPOINT_ISSUER=$(echo $result | jq -r \u0026#39;.authorization.parameters.workloadIdentityFederationIssuer\u0026#39;) # Service Endpoint Subject SERVICE_ENDPOINT_SUBJECT=$(echo $result | jq -r \u0026#39;.authorization.parameters.workloadIdentityFederationSubject\u0026#39;) # Create Federated Credential Configuration params file params.json PARAMS_NAME=\u0026#34;$AZDO_PROJECT_NAME-federated-identity\u0026#34; PARAMS_ISSUER=\u0026#34;${SERVICE_ENDPOINT_ISSUER}\u0026#34; PARAMS_SUBJECT=\u0026#34;${SERVICE_ENDPOINT_SUBJECT}\u0026#34; PARAMS_DESCRIPTION=\u0026#34;Federation for Service Connection $AZDO_SERVICE_ENDPOINT_NAME in $AZDO_BASE_URL/$AZDO_PROJECT_NAME/_settings/adminservices?resourceId=$SERVICE_ENDPOINT_ID\u0026#34; # Create Or Update Federated Credential if ! az identity federated-credential list --identity-name $ID_NAME --resource-group $AZURE_RG | jq -e --arg NAME \u0026#34;$PARAMS_NAME\u0026#34; \u0026#39;.[] | select(.name == $NAME)\u0026#39; \u0026gt; /dev/null; then result=$(az identity federated-credential create --identity-name $ID_NAME --name $PARAMS_NAME --resource-group $AZURE_RG --audiences \u0026#34;api://AzureADTokenExchange\u0026#34; --issuer $SERVICE_ENDPOINT_ISSUER --subject $PARAMS_SUBJECT) else result=$(az identity federated-credential update --identity-name $ID_NAME --name $PARAMS_NAME --resource-group $AZURE_RG --audiences \u0026#34;api://AzureADTokenExchange\u0026#34; --issuer $SERVICE_ENDPOINT_ISSUER --subject $PARAMS_SUBJECT) fi Azure DevOps YAML Pipeline (Managed Identity) git clone https://$AZDO_ORGANIZATION_NAME@dev.azure.com/$AZDO_ORGANIZATION_NAME/$AZDO_PROJECT_NAME/_git/$AZDO_PROJECT_NAME cd $AZDO_PROJECT_NAME PIPELINE_DIR=\u0026#34;pipelines\u0026#34; IDENTITY_TYPE=\u0026#34;mi\u0026#34; # Create directory if not exists if [ ! -d \u0026#34;$PIPELINE_DIR\u0026#34; ]; then mkdir $PIPELINE_DIR fi # Store pipeline cat \u0026lt;\u0026lt;EOF \u0026gt; $PIPELINE_DIR/$IDENTITY_TYPE.yaml trigger: - main pool: vmImage: ubuntu-latest steps: - task: AzureCLI@2 inputs: azureSubscription: \u0026#39;${AZDO_SERVICE_ENDPOINT_NAME}\u0026#39; scriptType: \u0026#39;pscore\u0026#39; scriptLocation: \u0026#39;inlineScript\u0026#39; inlineScript: | az account show --query id -o tsv EOF # Commit pipeline git config --global user.name $GIT_USER git config --global user.email $GIT_EMAIL if ! git diff --quiet HEAD -- \u0026#34;./$PIPELINE_DIR/$IDENTITY_TYPE.yaml\u0026#34; ; then git add ./$PIPELINE_DIR/$IDENTITY_TYPE.yaml git commit -m \u0026#34;📊 Add or Update pipeline.\u0026#34; git push origin main else echo \u0026#34;Nothing to commit.\u0026#34; fi az devops configure --defaults organization=$AZDO_BASE_URL az pipelines create \\ --name \u0026#34;$IDENTITY_TYPE-pipeline\u0026#34; \\ --description \u0026#34;This is a sample pipeline to use federated identity\u0026#34; \\ --repository $AZDO_PROJECT_NAME \\ --repository-type tfsgit \\ --branch main \\ --yaml-path $PIPELINE_DIR/$IDENTITY_TYPE.yaml \\ --project $AZDO_PROJECT_NAME Important:\nEnsure \u0026ldquo;Allow scripts to access the OAuth token\u0026rdquo; is enabled to access the federated token in pipeline tasks. $(System.AccessToken) provides the pipeline identity token securely without storing any secrets. Best Practices Use Azure AD Federated Credentials: Configure pipelines to authenticate via Azure AD federated credentials rather than storing secrets directly. Enforce Least Privilege: Assign minimal necessary permissions to identities used by pipelines. Regular Audits: Frequently audit access logs and credential configurations to ensure ongoing security. Conclusion Implementing federated identity within your CI/CD pipelines enhances security, reduces complexity, and prevents secret sprawl. Leveraging Azure AD integration with GitHub Actions and Azure DevOps pipelines provides a robust, scalable, and secure approach to managing authentication without compromising operational efficiency.\n","date":"2025-03-25T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/03/federated-credentials-secure-azure-cicd/","title":"📘 Using Federated Credentials to Secure Azure CI/CD Pipelines"},{"content":"Introduction: Azure Changelog – Latest Updates \u0026amp; Enhancements Welcome to the Azure Changelog, your go-to source for the latest updates and enhancements in Microsoft Azure. In this edition, we will cover the most recent changes and improvements made to Azure services, tools, and features. Stay informed about the latest developments in the Azure ecosystem to optimize your cloud experience.\nKubenet Networking for Azure Kubernetes Service Retires on March 31, 2028 Azure Kubernetes Service (AKS) will officially retire kubenet networking on March 31, 2028. After this date, workloads using kubenet will no longer be supported, so it\u0026rsquo;s essential to migrate in advance to avoid disruptions.\nMicrosoft recommends transitioning to Azure Container Networking Interface (CNI) overlay, which offers the same IP address overlay architecture as kubenet while providing improved scalability and new capabilities. Follow the upgrade guide to ensure a smooth migration before the deadline.\nAzure Spring Apps Retirement: Service Ends on March 31, 2028 Microsoft has announced the retirement of Azure Spring Apps, including the Basic, Standard, and Enterprise plans, with a final retirement date of March 31, 2028.\nKey Dates March 17, 2025 – Azure Spring Apps enters a three-year sunset period. New customers will no longer be able to sign up. March 31, 2028 – All Azure Spring Apps plans will be fully retired, and instances will no longer be accessible. Migration Recommendations To ensure continued performance, scalability, and cost efficiency, Microsoft recommends migrating workloads to Azure Container Apps or Azure Kubernetes Service (AKS) before the retirement date.\nRequired Action To prevent service disruptions, plan and execute your migration before March 31, 2028. Microsoft provides migration tools, expert resources, and technical support to assist with the transition.\nFor detailed migration guidance, review the official retirement document.\n","date":"2025-03-18T07:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/03/azure-updates-march-18-2025/","title":"🔄 Azure updates for March 18, 2025"},{"content":"Introduction: GitHub Changelog – Latest Updates \u0026amp; Enhancements Stay up to date with the latest GitHub updates, features, and improvements designed to enhance your development experience. Whether it’s security and compliance advancements, performance optimizations, or new tools for automation and insights, this changelog keeps you informed about what’s new and how it can benefit your workflow.\nInspired by our previous release, working with Copilot Chat on GitHub has become even more seamless. You can instantly preview HTML files, edit files you’ve created, and work on issues right away. Several exciting new capabilities give you more control and flexibility.\nWhat’s new Preview your rendered HTML files directly in the side panel Edit files in the side panel to seamlessly refine and adjust them Generate and preview Mermaid diagrams for fast visualizations, whether they’re flowcharts or sequence diagrams Keep tabs on your issues in the same right side panel, ensuring you can tackle open tasks while discussing them Track issues or pull requests in responses that are rendered in a familiar GitHub style, making working with them easier In addition, you can enjoy a smoother streaming experience and enhanced rendering of attachments. Try it out See the updated experience in action by submitting any of the following example prompts:\nWhat are the last five pull requests I made? Create a commit flow diagram in a markdown file. List the latest issues assigned to me. Create a colored 3D Rubik’s cube using only HTML and CSS.\n","date":"2025-03-18T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/03/github-updates-march-18-2025/","title":"🔄 GitHub updates for March 18, 2025"},{"content":"Introduction GitHub Copilot is an AI-powered coding assistant developed by GitHub in collaboration with OpenAI. It acts as a pair programmer, providing real-time code suggestions, autocompletions, and entire function implementations based on context. Whether you\u0026rsquo;re writing JavaScript, Python, C#, or even Terraform, Copilot speeds up development and improves productivity.\nIn this article, we’ll explore what GitHub Copilot is, how it works, its benefits, limitations, and best practices for maximizing its potential.\nWhat is GitHub Copilot? GitHub Copilot is an AI-driven coding assistant that helps developers write code faster and more efficiently. It integrates seamlessly into Visual Studio Code, JetBrains, and other popular IDEs. Copilot uses OpenAI\u0026rsquo;s Codex model to analyze comments and existing code, generating intelligent code suggestions in real time.\nKey Features of GitHub Copilot ✔ Context-Aware Code Suggestions – Provides relevant autocompletions based on existing code.\n✔ Multi-Language Support – Works with Python, JavaScript, TypeScript, Go, Ruby, C#, Terraform, and more.\n✔ Entire Function Implementations – Suggests entire function bodies from just a function signature or comment.\n✔ Comment-Driven Development – Generates code based on natural language descriptions.\n✔ IDE Integration – Works inside VS Code, Neovim, JetBrains, and Visual Studio.\n✔ GitHub Copilot Chat – An AI assistant built into the IDE for real-time coding support, explanations, and debugging.\n✔ Code Explanations – Copilot can analyze and explain snippets of code, improving developer understanding.\n✔ Security Vulnerability Prevention – Detects and suggests fixes for insecure coding patterns.\n✔ Code Completion in Pull Requests – Provides AI-powered code suggestions directly within GitHub pull requests.\n✔ Terminal Commands Assistance – Offers intelligent suggestions for shell commands and CLI usage.\n✔ Copilot for CLI (Coming Soon) – Extends Copilot’s capabilities to the command line for automation and task execution.\nExample: Generating a Python Function With a simple comment, Copilot can generate a fully functional implementation:\n# Function to calculate the factorial of a number def factorial(n): if n == 0: return 1 return n * factorial(n - 1) How Does GitHub Copilot Work? GitHub Copilot leverages OpenAI’s Codex, a model trained on public code repositories, documentation, and other programming-related text. It processes the context within your editor and predicts the most relevant completion.\nHow Copilot Generates Code: Context Awareness – Reads the surrounding code, including variable names, function names, and comments. Natural Language Understanding – Uses comments and docstrings to infer developer intent. Code Prediction – Suggests lines or entire blocks of code based on recognized patterns. Refinement – Offers alternative completions, allowing developers to cycle through options. Where Copilot Works Best: Boilerplate code generation Automating repetitive tasks Generating test cases Writing documentation comments Benefits of Using GitHub Copilot ✅ Increases Productivity Copilot accelerates coding by suggesting functions, reducing time spent on routine tasks.\n✅ Improves Learning and Onboarding Junior developers and new team members can use Copilot to quickly understand syntax and patterns in unfamiliar languages.\n✅ Encourages Best Practices By suggesting structured implementations, Copilot promotes consistency in coding style.\n✅ Enhances Documentation and Comments Developers can write comments, and Copilot will generate corresponding code, reinforcing the importance of well-documented software.\n✅ Improves Security Awareness Copilot now identifies insecure coding patterns and suggests fixes, helping developers write more secure code.\nLimitations and Considerations While GitHub Copilot is powerful, it has some drawbacks:\n⚠️ Not Always Correct Copilot can generate code that has logic errors or security vulnerabilities. Always review its suggestions.\n⚠️ Limited Understanding of Business Logic It doesn\u0026rsquo;t grasp your application’s specific business rules, so critical thinking is required.\n⚠️ Potential Licensing Issues Copilot is trained on public repositories, and there may be concerns about code originality and compliance with licenses.\n⚠️ Limited CLI and Terminal Support (For Now) While GitHub Copilot is expanding to assist with CLI commands, it is still in early development.\nBest Practices for Using GitHub Copilot 💡 Use Copilot for Assistance, Not Replacement Treat Copilot as a helper, but always verify the code it suggests.\n💡 Write Descriptive Comments Clear comments lead to better suggestions. Instead of # get user data, write # Fetch user data from the API and return JSON response.\n💡 Validate Code Quality Use linters, unit tests, and security scans to ensure Copilot-generated code meets standards.\n💡 Customize Copilot Settings In VS Code, you can enable or disable Copilot for certain file types and tweak its behavior.\nFuture of AI-Powered Coding GitHub Copilot is just the beginning. AI-powered tools are rapidly advancing, with features like:\nCopilot Chat – Interactive AI assistants inside your IDE. AI-Powered Code Reviews – Tools that analyze pull requests for best practices. Copilot CLI (Coming Soon) – AI-driven command-line automation. Enhanced Security Features – More advanced vulnerability detection and secure coding suggestions. Full AI Pair Programming – AI that understands entire projects, not just code snippets. Conclusion GitHub Copilot is a game-changer for developers, enabling faster coding, improved learning, and more efficient workflows. However, it\u0026rsquo;s not a replacement for human expertise—developers should critically evaluate its suggestions.\nWould you like a guide on integrating Copilot into your VS Code workflow? Let me know in the comments! 🚀\n","date":"2025-03-15T07:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/03/github-copilot-the-ai-powered-coding-assistant/","title":"🚀 GitHub Copilot: The AI-Powered Coding Assistant"},{"content":"Introduction Infrastructure as Code (IaC) is a critical part of modern cloud development, allowing teams to define and manage infrastructure in a declarative and repeatable way. Two of the most popular IaC tools for Microsoft Azure are Azure Bicep and Terraform.\nBut which one should you use? This article compares Bicep and Terraform based on syntax, features, ease of use, ecosystem support, and real-world scenarios.\nWhat is Azure Bicep? Azure Bicep is a domain-specific language (DSL) developed by Microsoft as an abstraction over ARM (Azure Resource Manager) templates. It simplifies Azure infrastructure deployment by providing a cleaner syntax compared to JSON-based ARM templates.\nKey Features of Azure Bicep ✔ Declarative syntax: Simplifies Azure infrastructure provisioning.\n✔ Native Azure support: Built and maintained by Microsoft.\n✔ No state management required: Uses Azure’s existing infrastructure model.\n✔ Deep integration with Azure services: Works seamlessly with Microsoft tools like Azure DevOps.\n✔ Easier debugging compared to ARM templates: More human-readable and less verbose.\nExample Bicep Template Below is a simple example of a Bicep script to deploy an Azure Storage Account:\nparam storageAccountName string = \u0026#39;mystorageaccount\u0026#39; param location string = \u0026#39;eastus\u0026#39; resource storageAccount \u0026#39;Microsoft.Storage/storageAccounts@2021-09-01\u0026#39; = { name: storageAccountName location: location kind: \u0026#39;StorageV2\u0026#39; sku: { name: \u0026#39;Standard_LRS\u0026#39; } } What is Terraform? Terraform is an open-source, multi-cloud IaC tool developed by HashiCorp. Unlike Bicep, which is specific to Azure, Terraform supports multiple cloud providers, including AWS, Google Cloud, and Azure. It uses the HashiCorp Configuration Language (HCL) to define infrastructure.\nKey Features of Terraform ✔ Multi-cloud support: Works with Azure, AWS, GCP, and on-prem infrastructure.\n✔ State management: Keeps track of infrastructure state, allowing for drift detection.\n✔ Modular and reusable: Supports modules for reusable infrastructure components.\n✔ Extensive ecosystem: Large community with many pre-built modules.\n✔ Built-in dependency management: Ensures resources are created in the correct order.\nExample Terraform Template Below is a simple Terraform script to deploy an Azure Storage Account:\nprovider \u0026#34;azurerm\u0026#34; { features {} } resource \u0026#34;azurerm_storage_account\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;mystorageaccount\u0026#34; resource_group_name = \u0026#34;my-resource-group\u0026#34; location = \u0026#34;East US\u0026#34; account_tier = \u0026#34;Standard\u0026#34; account_replication_type = \u0026#34;LRS\u0026#34; } Terraform’s Multi-Provider Advantage Terraform is not just multi-cloud but multi-provider, meaning it can be used to provision non-cloud resources such as databases, SaaS applications, Kubernetes clusters, and even on-prem infrastructure.\nExamples of Terraform\u0026rsquo;s Multi-Provider System Cloud Providers: Azure, AWS, GCP SaaS Platforms: GitHub, Azure DevOps, Datadog, Okta Infrastructure: VMware, Cisco, Kubernetes, Helm Databases \u0026amp; Storage: PostgreSQL, MySQL, MongoDB, Azure SQL Example: Provisioning Azure + GitHub Repositories in Terraform Here’s an example of how Terraform can deploy both an Azure Storage Account and a GitHub repository within the same configuration:\n# Azure Provider provider \u0026#34;azurerm\u0026#34; { features {} } resource \u0026#34;azurerm_storage_account\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;mystorageaccount\u0026#34; resource_group_name = \u0026#34;my-resource-group\u0026#34; location = \u0026#34;East US\u0026#34; account_tier = \u0026#34;Standard\u0026#34; account_replication_type = \u0026#34;LRS\u0026#34; } # GitHub Provider provider \u0026#34;github\u0026#34; { token = var.github_token } resource \u0026#34;github_repository\u0026#34; \u0026#34;example_repo\u0026#34; { name = \u0026#34;my-terraform-repo\u0026#34; description = \u0026#34;This is managed by Terraform\u0026#34; visibility = \u0026#34;public\u0026#34; } With Terraform, this can be deployed in a single pipeline, making it much simpler to manage infrastructure across multiple platforms.\nChallenges of Mixing Bicep and Terraform in the Same Pipeline If you only use Bicep, you might struggle with managing non-Azure resources. In a DevOps pipeline, this creates challenges:\nMultiple IaC tools: You would need to manage Terraform for non-Azure resources and Bicep for Azure resources separately. Complexity in orchestration: A pipeline would need separate execution steps for Bicep and Terraform. State synchronization issues: Terraform tracks the entire infrastructure in a state file, while Bicep does not, making it harder to maintain consistency. Example Pipeline with Mixed Bicep and Terraform:\nStep 1: Deploy Azure resources with Bicep Step 2: Deploy GitHub repositories with Terraform Step 3: Deploy Kubernetes workloads with Helm/Terraform This makes the pipeline more complex compared to using Terraform alone.\nConclusion: Why Terraform is More Flexible While Bicep is great for Azure-native infrastructure, Terraform\u0026rsquo;s multi-provider support makes it a better choice if:\nYour pipeline needs to provision both Azure and non-Azure resources. You want to manage SaaS integrations (e.g., GitHub, Azure DevOps, Okta). You need a consistent state management approach across all platforms. If your entire infrastructure is Azure-only, Bicep is a strong choice. But for hybrid or multi-cloud environments, Terraform provides a more unified IaC experience.\nWould you like a guide on how to integrate Terraform into an Azure DevOps or GitHub Actions pipeline?\n","date":"2025-03-15T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/03/azure-bicep-vs-terraform/","title":"⚖️ Azure Bicep vs Terraform: Which One Should You Use?"},{"content":"Introduction: GitHub Changelog – Latest Updates \u0026amp; Enhancements Stay up to date with the latest GitHub updates, features, and improvements designed to enhance your development experience. Whether it’s security and compliance advancements, performance optimizations, or new tools for automation and insights, this changelog keeps you informed about what’s new and how it can benefit your workflow.\nIn this edition, we’re covering GitHub’s PCI DSS v4.0 compliance for enterprise customers and the general availability of GitHub Actions Performance Metrics, helping teams gain deeper insights into their CI/CD workflows. Let’s dive into the details! 🚀\nGitHub is now PCI DSS v4.0 compliant with our 4.0 service provider attestation available to customers GitHub’s Payment Card Industry Data Security Standard (PCI DSS) v4.0 service provider Attestation of Compliance (AoC) as well as the corresponding shared responsibility matrix has been completed. This report is the first time GitHub has provided a PCI DSS service provider report for our customers. This enables customers to meet their own PCI DSS compliance needs using GitHub as part of their development environment.\nGoing forward, GitHub intends to provide this attestation of compliance each year.\nIf you’re an Enterprise customer and need to obtain copies of GitHub’s AoC or Shared Responsibility Matrix, please reach out to your account manager.\nSee the PCI DSS v4.0 Compliance\nActions Performance Metrics are generally available and Enterprise-level metrics are in public preview Performance Metrics for GitHub Actions are now generally available for repositories and organizations. Repository members can view workflow and job performance data including queue times and failure rates going back as far as one year. Organization members can also view this data aggregated across all repositories in their organization. These metrics are available on all GitHub Cloud plans.\nIn addition, usage and performance metrics aggregated at the Enterprise level are now available in public preview to Enterprise admins. This includes usage metrics (ex. jobs run and minutes used), as well as performance metrics (ex. job failure rates and queue times) across all repositories and organizations in an enterprise. These metrics can be found in the Enterprise UI under the \u0026ldquo;Insights\u0026rdquo; tab.\nActions Performance Metrics See the Actions Performance Metrics\n","date":"2025-03-14T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/03/github-updates-march-14-2025/","title":"🔄 GitHub updates for March 14, 2025"},{"content":"Introduction Terraform is a powerful Infrastructure as Code (IaC) tool that enables you to define, provision, and manage Azure resources using declarative configuration files. This blog series, Zero to Hero: Terraform for Azure, will take you through Terraform from the basics to advanced topics, using hands-on examples tailored for Azure.\nIn this first post, we’ll focus on setting up your development environment and deploying your first resource on Azure using Terraform.\nPrerequisites Before we start, you need:\nAn Azure account (a free account works fine) Basic knowledge of Azure (nice to have, but not required) We’ll cover multiple setup options:\nLocal installation (best for long-term development) Using Docker (best for isolated environments) 1. Setting Up the Development Environment Option 1: Local Installation For local development, you need to install:\nTerraform\nDownload Terraform for your OS.\nVerify installation:\nterraform version Azure CLI\nInstall Azure CLI for authentication and resource management:\nWindows:\nwinget install --id Microsoft.AzureCLI -e macOS:\nbrew install azure-cli Linux (Debian-based):\ncurl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash Verify installation:\naz version Visual Studio Code\nInstall VS Code. Install the Terraform extension from the Marketplace. Option 2: Using Docker If you prefer an isolated environment, you can use Terraform inside a Docker container.\nInstall Docker.\nRun Terraform inside a container:\ndocker run --rm -it hashicorp/terraform:latest version To work with local files, mount a volume:\ndocker run --rm -it -v $(pwd):/app -w /app hashicorp/terraform:latest init 2. Authenticating with Azure To deploy resources, Terraform needs to authenticate with Azure.\nLogin using Azure CLI Open a terminal and log in:\naz login If using multiple subscriptions, set the desired one:\naz account set --subscription \u0026#34;\u0026lt;subscription-id\u0026gt;\u0026#34; Using a Service Principal (For Automation) For automation in CI/CD pipelines:\naz ad sp create-for-rbac --name terraform-sp --role Contributor --scopes /subscriptions/\u0026lt;subscription-id\u0026gt; --sdk-auth Copy the JSON output for use in Terraform.\n3. Writing Your First Terraform Configuration Let’s create a simple Terraform script to deploy an Azure Storage Account.\nStep 1: Initialize a Terraform Project Create a new directory:\nmkdir terraform-azure \u0026amp;\u0026amp; cd terraform-azure Create a new Terraform file:\ntouch main.tf Step 2: Define the Terraform Configuration Open main.tf in VS Code and add the following:\nterraform { required_providers { azurerm = { source = \u0026#34;hashicorp/azurerm\u0026#34; version = \u0026#34;~\u0026gt; 3.0\u0026#34; } } } provider \u0026#34;azurerm\u0026#34; { features {} } resource \u0026#34;azurerm_resource_group\u0026#34; \u0026#34;example\u0026#34; { name = \u0026#34;terraform-rg\u0026#34; location = \u0026#34;West Europe\u0026#34; } Step 3: Initialize Terraform Run:\nterraform init Step 4: Preview Changes terraform plan Step 5: Apply the Configuration terraform apply -auto-approve Once completed, your resource group will be created in Azure.\n4. Cleaning Up and Next Steps To remove the deployed resources:\nterraform destroy -auto-approve Next Steps In the next post, we’ll explore Terraform state management and remote backends.\nStay tuned for more hands-on Terraform learning! 🚀\n","date":"2025-03-10T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/03/zero-to-hero-terraform-for-azure-1/","title":"🖥️ From Zero to Hero: Terraform for Azure - Part 1"},{"content":"Securing Azure Identities: The “New” Perimeter in Cloud Security It’s no secret that the cloud has fundamentally changed how we approach cybersecurity. The days when a robust firewall was all you needed to keep attackers at bay are long gone. As cloud-native services increasingly move into the public sphere, identity has emerged as the new defensive perimeter—if an attacker compromises your identities and credentials, they’re essentially inside.\nWhy Identities Matter More Than Ever If you’ve participated in a cybersecurity roundtable recently, you’ve likely heard someone mention, “Identity is the new perimeter.” Historically, once you were inside a corporate network, you had broad access to internal systems—much like walking through a front door and freely wandering the house. However, the widespread adoption of cloud services—accessible from anywhere—has turned this model upside down.\nNavigating Azure Identities Given that identities are the linchpin of security, it’s crucial to understand the different identity types available in Azure. This variety can be a blessing or a curse. On one hand, multiple identity types allow for flexibility across diverse use cases; on the other, choosing the wrong type can inadvertently weaken your security posture.\nBelow is a quick overview of the most common identities in Azure; for the sake of brevity, we’ll focus primarily on user and service principal identities:\nUser Identities Member Users\nCreated and managed within Microsoft Entra ID (formerly Azure AD), or synced from on-premises Active Directory via Entra ID Connect. Guest Users\nExternal accounts invited through Azure AD B2B collaboration to access specific resources. Consumer Users\nManaged through Entra ID B2C, primarily for applications requiring customer-facing authentication. Service Principals Application-Based\nCreated through Azure’s Application Registrations. Managed Identities User Assigned: Created independently and can be assigned to multiple resources. System Assigned: Automatically spun up and managed by Azure for a specific resource; deleted when the resource is removed. Other Identity Types Device Identities: Entra ID registered, joined, or hybrid-joined devices. External Identities: Federated identities from other identity providers. Group Identities: Security groups or Microsoft 365 Groups in Entra ID—yes, groups can effectively act like identities. Role-Based Identities: Azure RBAC roles that grant specific privileges. Temporary Identities: Temporary Access Pass (TAP), offering time-limited access. Even if a group isn’t a “user” in the traditional sense, having the ability to access certain resources means it demands the same level of security and oversight as a standard user account.\nPractical Tips to Fortify Your Azure Identities Securing identities doesn’t have to be an uphill battle. Small, strategic steps can dramatically improve your security stance. Below are tried-and-tested measures for both users and workload identities.\nTips for User Accounts Enable Multi-Factor Authentication (MFA)\nIf you do just one thing, do this. MFA blocks the lion’s share of password-based attacks. Adopt Phishing-Resistant Methods\nEspecially for privileged roles—options like FIDO2 security keys or certificate-based authentication can significantly reduce phishing risk. Explore Passwordless Authentication\nServices like Windows Hello or FIDO2 keys offer both greater convenience and stronger security. Use Conditional Access Policies\nDefine when and where users can log in. For instance, block sign-ins from untrusted devices or geographies. Monitor \u0026amp; Review Frequently\nRegularly audit guest accounts and app permissions to maintain the principle of least privilege. Leverage Built-In Azure Identity Tools\nMicrosoft Entra and Azure AD Identity Protection can automatically flag high-risk activities like risky user or risky sign-in events. Tips for Workload Identities (Service Principals / Managed Identities) Adopt Managed Identities\nInstead of hardcoding credentials in applications, let Azure handle identity lifecycle management. This limits the risk of credential leaks. Enforce the Principle of Least Privilege\nDevelopment often requires broad privileges, but production environments demand precision. Narrow permissions before going live. Avoid Assigning Owners to High-Privilege Apps\nIf a low-privilege user is the “owner” of an app that has a powerful scope (e.g., ‘Directory.ReadWrite.All’), you’re creating an escalated privilege pathway. Continuously Monitor \u0026amp; Review\nReassess user and app permissions to ensure they remain aligned with operational needs. Securing Azure identities is no longer a “nice-to-have” but an absolute must in today’s threat landscape. By understanding the range of identity types available, choosing them wisely, and implementing robust security measures—from MFA and passwordless methods to managed identities—you’ll significantly decrease your organization’s risk. After all, identities are now your frontline defense. Keeping them secure keeps everything else safe, too.\n","date":"2025-02-20T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/02/securing-azure-identities/","title":"🔒 Securing Azure Identities"},{"content":"Keeping your GitHub repositories clean is crucial for maintainability. Over time, branches pile up, making it difficult to track what’s relevant. If you’re managing multiple repositories in an organization, manually identifying stale branches can be a hassle.\nLuckily, with the GitHub CLI (gh), you can automate this process and generate a report of all non-main branches along with their last authors.\nThis guide walks you through a Bash script that:\n✅ Retrieves all repositories in an organization\n✅ Lists branches, excluding main, master, and azure-master\n✅ Identifies the last commit author for each branch\n✅ Groups the results by author for better visibility\n🔧 Prerequisites Before running the script, make sure:\nYou have GitHub CLI (gh) installed and authenticated (gh auth login). You have appropriate permissions to list repositories and fetch branch details in your organization. You\u0026rsquo;re running a Unix-based system (Linux/macOS or WSL for Windows). 📜 The Script Here’s the complete Bash script to scan all repositories in your GitHub organization and generate a stale branch report:\n# Set Variables org=\u0026#34;\u0026lt;Replace with your GitHub Organization name\u0026gt;\u0026#34; raw_output_file=\u0026#34;branches.txt\u0026#34; report_file=\u0026#34;report.txt\u0026#34; # Clear previous output \u0026gt; \u0026#34;$raw_output_file\u0026#34; # Get the repositories as JSON and extract names repos=$(gh repo list \u0026#34;$org\u0026#34; --json name --jq \u0026#39;.[].name\u0026#39;) # Function to get branch author safely get_author() { local org=$1 local repo=$2 local branch=$3 local author # Try fetching author name author=$(gh api \u0026#34;/repos/$org/$repo/branches/$branch\u0026#34; --jq \u0026#39;.commit.commit.author.name\u0026#39; 2\u0026gt;/dev/null) # If author is empty, return \u0026#34;Unknown\u0026#34; if [[ -z \u0026#34;$author\u0026#34; ]]; then author=\u0026#34;Unknown\u0026#34; fi # Write to output file echo \u0026#34; - Author: $author\u0026#34; \u0026gt;\u0026gt; \u0026#34;$raw_output_file\u0026#34; } # Loop through each repository for repo in $repos; do echo \u0026#34;- repo: $repo\u0026#34; \u0026gt;\u0026gt; \u0026#34;$raw_output_file\u0026#34; # Get all branches in the repository branches=$(gh api \u0026#34;/repos/$org/$repo/branches\u0026#34; --jq \u0026#39;.[].name\u0026#39;) # Loop through each branch for branch in $branches; do # Skip master, azure-master, and main if [[ \u0026#34;$branch\u0026#34; == \u0026#34;master\u0026#34; || \u0026#34;$branch\u0026#34; == \u0026#34;azure-master\u0026#34; || \u0026#34;$branch\u0026#34; == \u0026#34;main\u0026#34; ]]; then continue fi echo \u0026#34; - Branch: $branch\u0026#34; \u0026gt;\u0026gt; \u0026#34;$raw_output_file\u0026#34; # Fetch branch author get_author \u0026#34;$org\u0026#34; \u0026#34;$repo\u0026#34; \u0026#34;$branch\u0026#34; done done declare -A author_repos # Declare an associative array # Ensure the array is cleared before each run unset author_repos declare -A author_repos # Clear previous report \u0026gt; \u0026#34;$report_file\u0026#34; # Read and process output file while IFS= read -r line; do if [[ $line == \u0026#34;- repo: \u0026#34;* ]]; then repo=$(echo \u0026#34;$line\u0026#34; | awk \u0026#39;{print $3}\u0026#39;) elif [[ $line == \u0026#34; - Branch: \u0026#34;* ]]; then branch=$(echo \u0026#34;$line\u0026#34; | awk \u0026#39;{print $3}\u0026#39;) elif [[ $line == \u0026#34; - Author: \u0026#34;* ]]; then author=$(echo \u0026#34;$line\u0026#34; | sed \u0026#39;s/ - Author: //\u0026#39;) # Extract author name # Store branch under author author_repos[\u0026#34;$author\u0026#34;]+=$\u0026#39;\\n\u0026#39;\u0026#34;- $repo -\u0026gt; $branch\u0026#34; fi done \u0026lt; \u0026#34;$raw_output_file\u0026#34; # Print grouped results for author in \u0026#34;${!author_repos[@]}\u0026#34;; do echo \u0026#34;Author: $author\u0026#34; \u0026gt;\u0026gt; \u0026#34;$report_file\u0026#34; echo \u0026#34;${author_repos[$author]}\u0026#34; \u0026gt;\u0026gt; \u0026#34;$report_file\u0026#34; echo \u0026gt;\u0026gt; \u0026#34;$report_file\u0026#34; done cat \u0026#34;$report_file\u0026#34; 📊 Example Output Once executed, the script produces a report grouped by author, making it easy to find out who owns stale branches:\nAuthor: Alice - repo1 -\u0026gt; feature/login-page - repo2 -\u0026gt; hotfix/payment-fix Author: Bob - repo3 -\u0026gt; refactor/api-updates - repo1 -\u0026gt; test/legacy-integration Author: Unknown - repo4 -\u0026gt; bugfix/session-timeout 🔥 Why This Matters Easier Maintenance – Identify branches that can be deleted or merged. Better Collaboration – Reach out to authors to confirm branch status. Improved Performance – Reducing unnecessary branches speeds up repository operations. You can extend this script further to:\n✅ Filter branches by last commit date\n✅ Automatically delete stale branches (with gh api -X DELETE)\n✅ Generate a GitHub issue or PR listing stale branches\nWould love to hear how you customize this for your workflow! 🚀\n","date":"2025-01-14T01:00:00Z","permalink":"/ideal-octo-guacamole/posts/2025/01/retrieve-stale-branches-github-organization/","title":"🚀 How to Retrieve Stale Branches Across All Repositories in a GitHub Organization"},{"content":"Azure Storage automatically stores multiple copies of your data to protect against failures, power outages, and even massive natural disasters. Redundancy ensures that your data remains available and durable even when failures occur.\nThis guide covers all redundancy options available in Azure Storage and how they impact data durability, availability, and failover scenarios.\n🌍 Primary Region Redundancy Azure Storage always maintains three copies of your data in the primary region. There are two replication options:\n🔹 LRS (Locally Redundant Storage)\n🔹 ZRS (Zone-Redundant Storage)\n🟢 Locally Redundant Storage (LRS) LRS synchronously copies your data three times within a single physical location in the primary region.\n✅ Lowest-cost option\n⚠️ Not recommended for applications requiring high availability\nLocally Redundant Storage (LRS) 🔵 Zone-Redundant Storage (ZRS) ZRS synchronously replicates data across three availability zones within the primary region.\n✅ Recommended for high-availability applications\n✅ Protects against data center failures\nZone Redundant Storage (ZRS) 🌎 Secondary Region Redundancy (Geo-Redundancy) For higher durability, Azure allows replicating data to a secondary region, located hundreds of miles away from the primary region.\nWhen creating a storage account, you select the primary region, and Azure assigns a paired secondary region (which cannot be changed).\nAzure Storage provides two geo-redundancy options:\n🔹 GRS (Geo-Redundant Storage)\n🔹 GZRS (Geo-Zone-Redundant Storage)\nKey Difference: In both cases, the secondary region always uses LRS (three copies) for durability. However, the primary region\u0026rsquo;s replication method differs.\n🟡 Geo-Redundant Storage (GRS) GRS copies data:\nSynchronously (LRS) within the primary region Asynchronously to a single physical location in the secondary region ✅ Protects against regional outages\n⚠️ Data in the secondary region is not readable unless failover occurs\nGeo-Redundant Storage (GRS) 🔴 Geo-Zone-Redundant Storage (GZRS) GZRS combines the benefits of ZRS + GRS:\nSynchronously (ZRS) replicates across three availability zones in the primary region Asynchronously copies to a single location in the secondary region ✅ Best for mission-critical applications\n✅ Protects against both zonal \u0026amp; regional failures\nGeo-Zone-Redundant Storage (GZRS) 📖 Read Access to Secondary Region By default, GRS and GZRS replicate data to a secondary region but do not allow direct access.\nHowever, if your application requires read access to the secondary region during a primary region outage, you can enable:\n🔹 Read-Access Geo-Redundant Storage (RA-GRS)\n🔹 Read-Access Geo-Zone-Redundant Storage (RA-GZRS)\n✅ Data can be read from the secondary region\n⚠️ Secondary region lags behind the primary (async replication)\nNote: In a disaster scenario, some data might be lost since replication to the secondary region is asynchronous.\nOverview 📊 Comparison: Durability \u0026amp; Availability Durability \u0026amp; Availability Parameters Parameter LRS ZRS (RA-)GRS (RA-)GZRS Durability (per year) ≥ 11 9\u0026rsquo;s ≥ 12 9\u0026rsquo;s ≥ 16 9\u0026rsquo;s ≥ 16 9\u0026rsquo;s Availability (read requests) ≥ 99.9% (99% for Cool/Archive) ≥ 99.9% (99% for Cool/Archive) ≥ 99.9% for GRS / 99.99% for RA-GRS ≥ 99.9% for GZRS / 99.99% for RA-GZRS Availability (write requests) ≥ 99.9% (99% for Cool/Archive) ≥ 99.9% (99% for Cool/Archive) ≥ 99.9% ≥ 99.9% Number of copies of data 3 copies (single location) 3 copies (across zones) 6 copies (3 primary + 3 secondary) 6 copies (ZRS primary + LRS secondary) Availability Based on Outage Scenarios Failure Scenario LRS ZRS (RA-)GRS (RA-)GZRS Node failure within a data center ✅ ✅ ✅ ✅ Single data center failure ❌ ✅ ✅ ✅ Primary region failure (regional outage) ❌ ❌ ✅ ✅ Read access to secondary during primary outage ❌ ❌ ✅ (RA-GRS) ✅ (RA-GZRS) 🏆 Which Azure Storage Redundancy Should You Choose? Use Case Best Option Cost-sensitive workloads, backups, non-critical data LRS High availability within the primary region ZRS Disaster recovery and regional failover protection GRS Mission-critical workloads requiring both zonal \u0026amp; regional protection GZRS Applications requiring immediate read access to secondary RA-GRS / RA-GZRS 🛠 Final Thoughts Azure Storage offers multiple redundancy options to ensure data durability and availability. Choosing the right replication strategy depends on:\n✔️ Business requirements – Do you need cross-region failover?\n✔️ Cost considerations – ZRS and GZRS are costlier but offer better availability.\n✔️ Read requirements – Do you need read access to the secondary region?\nIf you’re running mission-critical applications, GZRS (or RA-GZRS) is your best bet. Otherwise, ZRS or GRS might be sufficient depending on your redundancy needs.\n🚀 What’s your go-to storage redundancy option? Drop a comment below! 👇\n","date":"2023-03-20T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2023/03/azure-storage-redundancy-data-availability-durability/","title":"🔹 Azure Storage Redundancy: Ensuring Data Availability and Durability"},{"content":"What is Load Balancing? Load balancing is the even distribution of network traffic across a group of backend computing resources or servers. The primary goals of load balancing are:\n✅ Optimizing resource utilization\n✅ Maximizing throughput \u0026amp; performance\n✅ Minimizing response time\n✅ Ensuring high availability\n✅ Preventing overload on a single resource\nIn Azure, there are multiple load-balancing options, each designed for different traffic types and use cases.\n🔍 Azure Load Balancing Options Service Scope Recommended for Layer Azure Load Balancer Regional Non-HTTP(S) workloads Layer 4 Traffic Manager Global DNS-based traffic routing Layer 7 (DNS) Azure Application Gateway Regional HTTP(S) web traffic Layer 7 Azure Front Door Global Web applications, API acceleration Layer 7 Load Balancing Decision Tree Now, let’s explore each of these services in detail.\n🌍 Azure Load Balancer (ALB) Azure Load Balancer Azure Load Balancer is a Layer 4 (TCP/UDP) load-balancing service designed for high-performance and ultra-low-latency traffic. It efficiently distributes inbound and outbound traffic while ensuring high availability across Availability Zones.\nTypes of Azure Load Balancers Type Purpose Public Load Balancer Distributes internet-facing traffic across VMs in a VNet. Internal Load Balancer Distributes private network traffic within Azure. ALB Public vs Internal Availability Zone Configurations Mode Behavior Zone Redundant Uses a single IP, surviving zone failures. Zonal Restricts traffic to a specific zone. ALB Zone Redundant Standard vs. Basic Load Balancer Feature Standard Basic Backend pool size 1000 VMs 300 VMs Health probes TCP, HTTP, HTTPS TCP, HTTP Secure by default ✅ Yes ❌ No HA Ports ✅ Available ❌ Not available SLA ✅ 99.99% ❌ Not available 🌐 Azure Traffic Manager (ATM) Azure Traffic Manager Traffic Manager is a DNS-based global load balancer, designed to distribute traffic across multiple Azure regions. It does not directly route traffic—instead, it resolves requests to the nearest healthy backend.\nHow It Works 1️⃣ A client requests a domain (e.g., app.contoso.com).\n2️⃣ The DNS system redirects to contoso.trafficmanager.net.\n3️⃣ Traffic Manager selects a backend using health checks \u0026amp; routing rules.\n4️⃣ The client receives the IP of the closest, available backend and connects directly.\nAzure Traffic Manager Setup Routing Methods Routing Method Use Case Priority Primary backend with failover options. Weighted Distribute traffic based on weights. Performance Route traffic to the closest backend. Geographic Route traffic based on user location. MultiValue Return multiple healthy endpoints. Subnet Route based on user IP ranges. Traffic Manager Routing Traffic Manager is ideal for:\n✔️ Failover between Azure regions\n✔️ Multi-region deployments\n✔️ Hybrid cloud environments\n🔹 Azure Application Gateway (APG) Azure Application Gateway Application Gateway is a Layer 7 load balancer designed specifically for HTTP(S) traffic. It provides advanced web traffic routing, SSL offloading, and Web Application Firewall (WAF) integration.\nKey Features ✅ Path-based routing → Direct requests to different backends based on URL paths.\n✅ Session affinity → Keep users connected to the same backend server.\n✅ SSL Termination → Offload SSL decryption to reduce backend CPU usage.\n✅ Autoscaling → Dynamically scale based on traffic load.\nApplication Gateway Flow Best for:\n✔️ Web applications that require advanced traffic routing.\n✔️ Security-conscious deployments using WAF protection.\n🌎 Azure Front Door (AFD) Azure Front Door Azure Front Door is a global Layer 7 service that combines load balancing, caching, acceleration, and security into one solution. It ensures high availability and low-latency for web applications.\nKey Capabilities ✅ Global HTTP(S) load balancing → Route traffic to the nearest healthy region.\n✅ SSL offloading \u0026amp; URL rewriting → Enhance security \u0026amp; performance.\n✅ Caching \u0026amp; acceleration → Reduce latency via Edge locations.\n✅ DDoS Protection \u0026amp; WAF → Secure web apps from threats.\n💡 Front Door vs. Traffic Manager:\n🔹 Front Door → Routes traffic in real-time based on latency.\n🔹 Traffic Manager → Routes via DNS resolution, which is slower due to caching.\nBest for:\n✔️ Global applications that need low latency.\n✔️ Web APIs requiring intelligent traffic routing.\n🌍 Global vs. Regional Load Balancing Service Scope Use Case Azure Front Door Global HTTP(S) traffic acceleration \u0026amp; load balancing. Traffic Manager Global DNS-based traffic routing. Application Gateway Regional Web application load balancing. Azure Load Balancer Regional Non-HTTP(S) workloads. 💡 When to Choose Which? Scenario Recommended Service Distribute global HTTP(S) traffic Azure Front Door Route traffic between regions via DNS Traffic Manager Load balance internal traffic within Azure Azure Load Balancer Optimize web application performance Azure Application Gateway 📌 Final Thoughts Azure offers multiple load balancing solutions, each designed for specific traffic types, regions, and use cases. Whether you\u0026rsquo;re building a global web application or optimizing regional traffic, choosing the right service is key to maximizing performance, availability, and security.\n💡 Summary:\n✔️ Use Front Door for global web acceleration.\n✔️ Use Traffic Manager for DNS-based failover.\n✔️ Use Application Gateway for web app security \u0026amp; routing.\n✔️ Use Azure Load Balancer for high-performance, low-latency workloads.\n","date":"2022-06-17T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2022/06/azure-load-balancing-explained/","title":"🔍 Azure Load Balancing Explained: Choosing the Right Option"},{"content":"This blog post captures my notes from the AZ-700 course, which is designed to teach Network Engineers how to design, implement, and maintain Azure networking solutions. The course covers a wide range of networking topics, including:\nDesigning, implementing, and managing core Azure networking infrastructure Hybrid networking connections for on-premises integration Load balancing strategies for optimizing traffic distribution Routing and private access to Azure services Network security and traffic filtering Monitoring and troubleshooting network connectivity 1. Virtual Networks (VNets) Azure Virtual Networks (VNets) are the backbone of networking in Azure, allowing resources to communicate securely.\nVNet Capabilities Azure VNets support:\n✅ Communication with the internet\n✅ Communication between Azure resources\n✅ Secure connectivity to on-premises networks\n✅ Traffic filtering using NSGs (Network Security Groups)\n✅ Routing network traffic efficiently\nVNet Address Space Azure VNets use private IP address ranges as defined in RFC 1918:\nIP Range Prefix 10.0.0.0 - 10.255.255.255 10/8 172.16.0.0 - 172.31.255.255 172.16/12 192.168.0.0 - 192.168.255.255 192.168/16 Subnet Allocation Azure reserves 5 IPs per subnet:\n🔹 x.x.x.0 → Network address\n🔹 x.x.x.1 → Default gateway\n🔹 x.x.x.2 \u0026amp; x.x.x.3 → Azure DNS mapping\n🔹 x.x.x.255 → Broadcast address\n2. Scopes in Azure In Azure, every resource must have a unique name within its defined scope. Scopes are hierarchical:\n1️⃣ Global (e.g., Storage Accounts)\n2️⃣ Management Group\n3️⃣ Subscription\n4️⃣ Resource Group (e.g., VNets)\n5️⃣ Resource (individual resource instances)\n3. Regions \u0026amp; Availability Zones Regions \u0026amp; Subscriptions Resources in a VNet must be in the same region, but cross-region connectivity is possible. VNets can be linked across different subscriptions. Availability Zones (AZs) Availability Zones provide high availability by distributing resources across physically separate data centers within a region.\n🔹 Zonal Services → Resources pinned to a specific zone\n🔹 Zone-Redundant Services → Automatically replicated across zones\n🔹 Non-Regional Services → Resilient to zone-wide and region-wide failures\n4. Public IPs in Azure Public IPs enable external communication for Azure resources. They can be static (unchanging) or dynamic (reassigned upon restart).\nPublic IP Type Allocation Security Zone Support Basic SKU Static / Dynamic Open by default ❌ No AZ support Standard SKU Static only Secure by default (NSG required) ✅ Zone-redundant 5. DNS Resolution in Azure Azure provides both public and private DNS services to resolve domain names.\nDNS Public DNS Azure DNS manages internet-facing domain names and supports:\n🔹 A / AAAA records for IPv4/IPv6\n🔹 CNAME records for aliasing domains\nPrivate DNS For internal name resolution within VNets, Azure supports:\n1️⃣ Azure DNS Private Zones\n2️⃣ Azure-provided name resolution\n3️⃣ Custom DNS servers\n🔹 Azure\u0026rsquo;s built-in DNS resolver: 168.63.129.16\nDNS forwarding allows on-premises resources to resolve Azure hostnames, ensuring seamless hybrid connectivity.\n📌 Example: Conditional Forwarding\nTo resolve hostnames across VNets, use custom DNS servers with conditional forwarding rules.\n6. VNet Peering for Cross-Network Connectivity Azure VNet Peering allows seamless communication between VNets without a VPN.\nPeering Type Scope Performance Regional Peering Same Azure region High bandwidth, low latency Global Peering Cross-region Uses Azure backbone VNet Peering Benefits ✅ Secure private communication (no internet exposure)\n✅ No need for VPN gateways\n✅ Supports NSGs for access control\n✅ Works across subscriptions and tenants\nPeering 7. Gateway Transit for Shared VPN Access Gateway Transit allows one VNet to use another VNet’s VPN gateway for cross-premises connectivity.\n💡 Use case: A hub-and-spoke topology where a single gateway in the hub VNet provides VPN access to multiple spokes.\nGateway Transit 8. Azure Traffic Routing Azure manages traffic routing through:\n1️⃣ System Routes (default routes created by Azure) 🔹 Internet traffic → Sent via the default Internet Gateway\n🔹 Private traffic → Stays within the VNet\n2️⃣ Custom Routes (UDRs - User Defined Routes) Use route tables to override system routes.\n💡 Example: Direct traffic to a firewall appliance instead of the default gateway.\nDefault Route Table Source Destination Next Hop Default 0.0.0.0/0 Internet Default 10.0.0.0/8 None Default 192.168.0.0/16 None Final Thoughts This post provides a comprehensive summary of key Azure networking concepts from AZ-700. Understanding VNets, peering, DNS, and routing is essential for designing scalable, secure, and high-performing cloud networks.\n📌 Key Takeaways:\n✅ Master VNet and subnet design to optimize address space\n✅ Use peering and gateway transit for hybrid connectivity\n✅ Leverage DNS solutions to simplify name resolution\n✅ Control traffic with NSGs \u0026amp; UDRs for security and compliance\n🔥 If you\u0026rsquo;re studying for AZ-700, focus on hands-on labs to reinforce concepts! 🚀\n","date":"2022-06-03T06:00:00Z","permalink":"/ideal-octo-guacamole/posts/2022/06/az-700-prep-highlights/","title":"📘 AZ-700 Prep Highlights"}]